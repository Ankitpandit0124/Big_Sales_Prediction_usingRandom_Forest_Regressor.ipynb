# -*- coding: utf-8 -*-
"""Big_Sales_Prediction_usingRandom_Forest_Regressor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13qkZDUiMqWE3Y1t0hOhdew_CxT_1AgpI

###Big Sales Prediction using Random Forest Regressor

# Get Understanding about Data Set

There are 12 variables in Dataset

1. Item_Identifier
2. Item_Weight
3. Item_Fat_Content
4. Item_Visibility
5. Item_Type
6. Item_MRP
7. Outler_Identifier
8. Outlet_Establishment_Year
9. Outlet_Size
10. Outlet_Location_Type
11. Outlet_Type
12. Item_Outlet_Sales

# Import Library
"""

import pandas as pd

import numpy as np

"""# New Section

# Import CSV as DataFrame

Use URL of file Directory
"""

df=pd.read_csv(r'https://raw.githubusercontent.com/YBI-Foundation/Dataset/main/Big%20Sales%20Data.csv')

"""# Get the First Five Row Of DataFrame"""

df.head()

"""# Get Information Of DataFrame"""

df.info()

"""# Get Column Name"""

df.columns

"""# Get The Summary Statistics"""

df.describe()

"""# Get Missing Value Complete"""

df['Item_Weight'].fillna(df.groupby(['Item_Type'])['Item_Weight'].transform('mean'),inplace=True)

df.info()

df.describe()

import seaborn as sns
sns.pairplot(df)

"""# GetCatogaries and Count of Categorical Variables"""

df[['Item_Identifier']].value_counts()

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content':{'LF':'Low Fat','reg':'Regular','Low Fat':'Low Fat'}},inplace=True)

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content':{'Low Fat':0,'Regular':1}},inplace=True)

df[['Item_Type']].value_counts()

df.replace({'Item_Type':{'Fruits and Vegitable':0,'Snack Foods':0,'Household':1,
                         'Frozen Food':0,'Dairy':0,'Baking Goods':0,
                         'canned':0,'Health and Hygine':1,
                         'Meat':0,'Soft Drinks':0,'Breads':0,'Hard Drinks':0,
                         'Others':2,'Starchy Foods':0,'Breakfast':0,'Seafood':0
                         }},inplace=True)

df[['Item_Type']].value_counts()

df[['Outlet_Identifier']].value_counts()

df.replace({'outlet_identifier':{'OUT027':0,'OUT013':1,
                                'OUT049':2,'OUT046':3,'OUT035':4,
                                 'OUT045':5,'OUT018':6,
                                 'OUT017':7,'OUT010':8,'OUT019':9
                                 }},inplace=True)

df[['Outlet_Size']].value_counts()

df.replace({'outlet_Size':{'Small':0,'Medium':1,'High':2}},inplace=True)

df[['Outlet_Size']].value_counts()

df[['Outlet_Location_Type']].value_counts()

df.replace({'outlet_Location_Type':{'Tier 3':0,'Tier 2':1,'Tier 1':2}},inplace=True)

df[['Outlet_Location_Type']].value_counts()

df[['Outlet_Type']].value_counts()

df.replace({'Outlet_Type':{'Supermarket Type1':0,'Supermarket Type2':1,
                           'Grocery Store':2,'Supermarket Type3':3}},inplace=True)

df[['Outlet_Type']].value_counts()

df.head()

df.info()

"""# Get Shape Of DataFrame"""

df.shape

"""# Define y(dependent or label or target variable) and x(independent or features or attribute variable)"""

y=df['Item_Outlet_Sales']

y.shape

y

x=df[['Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type',
       'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year',
       'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']]

x=df.drop(['Item_Identifier',],axis=1)

x.shape

x

"""# Get X Variables standardized

Standardization can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Geometrically speaking, it translates the data to the mean vector of original data to the origin and squishes or expands the points if std is 1 respectively.
"""

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

x_std=df[['Item_Weight','Item_Visibility','Item_MRP']]

x_std=sc.fit_transform(x_std)

x_std

x[['Item_Weight','Item_Visibility','Item_MRP']]=pd.DataFrame(x_std,columns=[['Item_Weight','Item_Visibility','Item_MRP']])

x

"""# Get Train Test Split"""

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=2529   )

x_train.shape,x_test.shape,y_train.shape,y_test.shape

"""# Get Model Train"""

from sklearn.ensemble import RandomForestRegressor

rfr=RandomForestRegressor(random_state=2529)

rfr.fit(x_train,y_train)

from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder # Import OneHotEncoder
import pandas as pd # Import pandas for easier data manipulation if needed

# Assuming x_train is a pandas DataFrame, identify categorical columns
categorical_cols = x_train.select_dtypes(include=['object']).columns

# Create a OneHotEncoder object
enc = OneHotEncoder(handle_unknown='ignore')

# Fit the encoder on the categorical columns and transform the data
num_cat_features = enc.fit_transform(x_train[categorical_cols])

# Convert the transformed data back to a DataFrame
num_cat_features_df = pd.DataFrame(num_cat_features.toarray())

# Get the names of the one-hot encoded columns
new_col_names = enc.get_feature_names_out(categorical_cols)
num_cat_features_df.columns = new_col_names

# Drop original categorical columns from x_train
x_train = x_train.drop(categorical_cols, axis=1)

# Concatenate the numerical representation of categorical features with the rest of x_train
x_train = pd.concat([x_train, num_cat_features_df], axis=1)

# ... (Repeat the same encoding process for x_test)

# Initialize and fit the model
rfr = RandomForestRegressor(random_state=2529)
rfr.fit(x_train, y_train)

"""# Get Model Pridiction"""

y_pred=rfr.predict(x_test)

y_pred.shape

y_pred

